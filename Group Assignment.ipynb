{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the normalized DataFrame from the CSV file\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Specify target column name\n",
        "target_column = 'Default'  # Replace 'Default' with the name of your target column\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=[target_column])\n",
        "y = normalized_df[target_column]\n",
        "\n",
        "# Add constant to features for the intercept term\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the summary of the regression model\n",
        "regression_summary = model.summary()\n",
        "\n",
        "# Display the regression summary\n",
        "print(\"Regression Summary:\")\n",
        "print(regression_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz1dQbzYdeiq",
        "outputId": "f995806f-1a37-4621-e928-6ed1b1ed8d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Summary:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                Default   R-squared:                       0.082\n",
            "Model:                            OLS   Adj. R-squared:                  0.082\n",
            "Method:                 Least Squares   F-statistic:                     989.8\n",
            "Date:                Tue, 09 Apr 2024   Prob (F-statistic):               0.00\n",
            "Time:                        14:27:25   Log-Likelihood:                -60753.\n",
            "No. Observations:              255327   AIC:                         1.216e+05\n",
            "Df Residuals:                  255303   BIC:                         1.218e+05\n",
            "Df Model:                          23                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================================\n",
            "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------------\n",
            "const                            0.1057      0.002     64.643      0.000       0.103       0.109\n",
            "Age                             -0.1826      0.002    -88.356      0.000      -0.187      -0.179\n",
            "Income                          -0.1095      0.002    -52.038      0.000      -0.114      -0.105\n",
            "LoanAmount                       0.0959      0.002     45.656      0.000       0.092       0.100\n",
            "CreditScore                     -0.0386      0.002    -18.367      0.000      -0.043      -0.034\n",
            "MonthsEmployed                  -0.1073      0.002    -51.400      0.000      -0.111      -0.103\n",
            "NumCreditLines                   0.0081      0.001     14.837      0.000       0.007       0.009\n",
            "InterestRate                     0.1454      0.002     69.036      0.000       0.141       0.149\n",
            "DTIRatio                         0.0207      0.002      9.831      0.000       0.017       0.025\n",
            "HasMortgage                     -0.0146      0.001    -12.035      0.000      -0.017      -0.012\n",
            "HasDependents                   -0.0222      0.001    -18.266      0.000      -0.025      -0.020\n",
            "HasCoSigner                     -0.0252      0.001    -20.727      0.000      -0.028      -0.023\n",
            "Education_Bachelor's             0.0316      0.001     28.103      0.000       0.029       0.034\n",
            "Education_High School            0.0392      0.001     34.751      0.000       0.037       0.041\n",
            "Education_Master's               0.0195      0.001     17.264      0.000       0.017       0.022\n",
            "Education_PhD                    0.0154      0.001     13.584      0.000       0.013       0.018\n",
            "EmploymentType_Full-time         0.0052      0.001      4.621      0.000       0.003       0.007\n",
            "EmploymentType_Part-time         0.0297      0.001     26.346      0.000       0.027       0.032\n",
            "EmploymentType_Self-employed     0.0252      0.001     22.320      0.000       0.023       0.027\n",
            "EmploymentType_Unemployed        0.0456      0.001     40.363      0.000       0.043       0.048\n",
            "MaritalStatus_Divorced           0.0442      0.001     43.420      0.000       0.042       0.046\n",
            "MaritalStatus_Married            0.0234      0.001     22.981      0.000       0.021       0.025\n",
            "MaritalStatus_Single             0.0381      0.001     37.466      0.000       0.036       0.040\n",
            "LoanPurpose_Auto                 0.0245      0.001     19.404      0.000       0.022       0.027\n",
            "LoanPurpose_Business             0.0285      0.001     22.691      0.000       0.026       0.031\n",
            "LoanPurpose_Education            0.0227      0.001     18.053      0.000       0.020       0.025\n",
            "LoanPurpose_Home                 0.0067      0.001      5.357      0.000       0.004       0.009\n",
            "LoanPurpose_Other                0.0233      0.001     18.484      0.000       0.021       0.026\n",
            "==============================================================================\n",
            "Omnibus:                    98404.508   Durbin-Watson:                   1.999\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           293067.028\n",
            "Skew:                           2.104   Prob(JB):                         0.00\n",
            "Kurtosis:                       6.136   Cond. No.                     2.64e+16\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 4.25e-27. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting"
      ],
      "metadata": {
        "id": "ddVOwAKxbtWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from scipy.stats import randint\n",
        "import multiprocessing\n",
        "\n",
        "# Load the modified DataFrame\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=['Default'])  # Features\n",
        "y = normalized_df['Default']  # Target variable\n",
        "\n",
        "# Apply SMOTE to the training data only\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': randint(3, 10),\n",
        "    'learning_rate': [0.1, 0.05, 0.01]\n",
        "}\n",
        "\n",
        "# Initialize Gradient Boosting classifier\n",
        "classifier = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Initialize RandomizedSearchCV with parallel processing\n",
        "n_cores = multiprocessing.cpu_count()\n",
        "random_search = RandomizedSearchCV(estimator=classifier, param_distributions=param_grid, n_iter=5, cv=3, scoring='f1', random_state=42, n_jobs=n_cores)\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Make predictions on the validation data using the best model\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_val)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_val, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wCLbAqZbwMD",
        "outputId": "609407c2-5365-4819-abd3-38396695fa9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 152}\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91     45188\n",
            "           1       0.93      0.88      0.90     45084\n",
            "\n",
            "    accuracy                           0.91     90272\n",
            "   macro avg       0.91      0.91      0.91     90272\n",
            "weighted avg       0.91      0.91      0.91     90272\n",
            "\n",
            "Confusion Matrix:\n",
            "[[42340  2848]\n",
            " [ 5523 39561]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = best_model.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unFhrP2Jb2AN",
        "outputId": "362956aa-82f3-40f8-f773-d1bc65297c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cat Boost Classifier\n"
      ],
      "metadata": {
        "id": "RPV9xfvz8DIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CatBoost Classifier is a gradient boosting algorithm specifically designed to work well with categorical features. It's an efficient implementation of gradient boosting for decision trees and is particularly useful for datasets with categorical features and large numbers of observations. CatBoost handles categorical features internally without the need for preprocessing like one-hot encoding.\n",
        "\n"
      ],
      "metadata": {
        "id": "89wGpMNF8QdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "I1UWzdHC2um2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import multiprocessing\n",
        "\n",
        "# Load data\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=[\"Default\"])  # Features\n",
        "y = normalized_df[\"Default\"]  # Target variable\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize CatBoost Classifier\n",
        "catboost = CatBoostClassifier()\n",
        "\n",
        "# Define parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'iterations': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'depth': [4, 6, 8, 10],\n",
        "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
        "    'border_count': [32, 64, 128],\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV with parallel processing\n",
        "n_cores = multiprocessing.cpu_count()\n",
        "random_search = RandomizedSearchCV(estimator=catboost, param_distributions=param_dist, n_iter=20, cv=3, scoring='f1', random_state=42, n_jobs=n_cores)\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_catboost = random_search.best_estimator_\n",
        "\n",
        "# Evaluate model on validation set using best parameters\n",
        "y_pred_val = best_catboost.predict(X_val)\n",
        "print(\"Validation Set Performance with Best Parameters:\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "s7E3OFqN8OoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3304aa4d-05d6-4a2a-ecaf-82621bc1fa2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6094321\ttotal: 61.5ms\tremaining: 18.4s\n",
            "1:\tlearn: 0.5420694\ttotal: 122ms\tremaining: 18.1s\n",
            "2:\tlearn: 0.4926297\ttotal: 179ms\tremaining: 17.7s\n",
            "3:\tlearn: 0.4565312\ttotal: 253ms\tremaining: 18.7s\n",
            "4:\tlearn: 0.4273003\ttotal: 315ms\tremaining: 18.6s\n",
            "5:\tlearn: 0.4034218\ttotal: 371ms\tremaining: 18.2s\n",
            "6:\tlearn: 0.3854213\ttotal: 427ms\tremaining: 17.9s\n",
            "7:\tlearn: 0.3707935\ttotal: 482ms\tremaining: 17.6s\n",
            "8:\tlearn: 0.3603769\ttotal: 542ms\tremaining: 17.5s\n",
            "9:\tlearn: 0.3509116\ttotal: 602ms\tremaining: 17.5s\n",
            "10:\tlearn: 0.3441678\ttotal: 656ms\tremaining: 17.2s\n",
            "11:\tlearn: 0.3388437\ttotal: 713ms\tremaining: 17.1s\n",
            "12:\tlearn: 0.3340740\ttotal: 774ms\tremaining: 17.1s\n",
            "13:\tlearn: 0.3304166\ttotal: 834ms\tremaining: 17s\n",
            "14:\tlearn: 0.3275213\ttotal: 891ms\tremaining: 16.9s\n",
            "15:\tlearn: 0.3249003\ttotal: 984ms\tremaining: 17.5s\n",
            "16:\tlearn: 0.3229320\ttotal: 1.08s\tremaining: 18s\n",
            "17:\tlearn: 0.3209652\ttotal: 1.22s\tremaining: 19s\n",
            "18:\tlearn: 0.3194361\ttotal: 1.33s\tremaining: 19.6s\n",
            "19:\tlearn: 0.3182188\ttotal: 1.46s\tremaining: 20.5s\n",
            "20:\tlearn: 0.3171916\ttotal: 1.6s\tremaining: 21.3s\n",
            "21:\tlearn: 0.3161153\ttotal: 1.74s\tremaining: 22s\n",
            "22:\tlearn: 0.3153024\ttotal: 1.87s\tremaining: 22.5s\n",
            "23:\tlearn: 0.3147045\ttotal: 2s\tremaining: 23s\n",
            "24:\tlearn: 0.3140348\ttotal: 2.12s\tremaining: 23.4s\n",
            "25:\tlearn: 0.3134668\ttotal: 2.25s\tremaining: 23.7s\n",
            "26:\tlearn: 0.3129817\ttotal: 2.39s\tremaining: 24.1s\n",
            "27:\tlearn: 0.3125574\ttotal: 2.53s\tremaining: 24.6s\n",
            "28:\tlearn: 0.3121961\ttotal: 2.65s\tremaining: 24.8s\n",
            "29:\tlearn: 0.3118131\ttotal: 2.79s\tremaining: 25.1s\n",
            "30:\tlearn: 0.3114400\ttotal: 2.9s\tremaining: 25.2s\n",
            "31:\tlearn: 0.3110844\ttotal: 3.04s\tremaining: 25.4s\n",
            "32:\tlearn: 0.3107680\ttotal: 3.16s\tremaining: 25.6s\n",
            "33:\tlearn: 0.3104850\ttotal: 3.27s\tremaining: 25.6s\n",
            "34:\tlearn: 0.3101719\ttotal: 3.41s\tremaining: 25.8s\n",
            "35:\tlearn: 0.3098442\ttotal: 3.53s\tremaining: 25.9s\n",
            "36:\tlearn: 0.3095894\ttotal: 3.68s\tremaining: 26.1s\n",
            "37:\tlearn: 0.3093727\ttotal: 3.79s\tremaining: 26.1s\n",
            "38:\tlearn: 0.3091203\ttotal: 3.9s\tremaining: 26.1s\n",
            "39:\tlearn: 0.3089467\ttotal: 3.95s\tremaining: 25.7s\n",
            "40:\tlearn: 0.3087168\ttotal: 4.01s\tremaining: 25.3s\n",
            "41:\tlearn: 0.3085108\ttotal: 4.07s\tremaining: 25s\n",
            "42:\tlearn: 0.3083191\ttotal: 4.13s\tremaining: 24.7s\n",
            "43:\tlearn: 0.3081159\ttotal: 4.19s\tremaining: 24.4s\n",
            "44:\tlearn: 0.3079480\ttotal: 4.25s\tremaining: 24.1s\n",
            "45:\tlearn: 0.3077569\ttotal: 4.31s\tremaining: 23.8s\n",
            "46:\tlearn: 0.3075782\ttotal: 4.36s\tremaining: 23.5s\n",
            "47:\tlearn: 0.3074077\ttotal: 4.43s\tremaining: 23.3s\n",
            "48:\tlearn: 0.3072490\ttotal: 4.5s\tremaining: 23s\n",
            "49:\tlearn: 0.3070948\ttotal: 4.55s\tremaining: 22.8s\n",
            "50:\tlearn: 0.3069624\ttotal: 4.61s\tremaining: 22.5s\n",
            "51:\tlearn: 0.3068134\ttotal: 4.66s\tremaining: 22.2s\n",
            "52:\tlearn: 0.3066792\ttotal: 4.72s\tremaining: 22s\n",
            "53:\tlearn: 0.3065614\ttotal: 4.78s\tremaining: 21.8s\n",
            "54:\tlearn: 0.3063993\ttotal: 4.84s\tremaining: 21.5s\n",
            "55:\tlearn: 0.3062787\ttotal: 4.89s\tremaining: 21.3s\n",
            "56:\tlearn: 0.3061110\ttotal: 4.96s\tremaining: 21.1s\n",
            "57:\tlearn: 0.3059592\ttotal: 5.01s\tremaining: 20.9s\n",
            "58:\tlearn: 0.3058554\ttotal: 5.07s\tremaining: 20.7s\n",
            "59:\tlearn: 0.3057322\ttotal: 5.12s\tremaining: 20.5s\n",
            "60:\tlearn: 0.3055872\ttotal: 5.18s\tremaining: 20.3s\n",
            "61:\tlearn: 0.3054495\ttotal: 5.24s\tremaining: 20.1s\n",
            "62:\tlearn: 0.3053234\ttotal: 5.3s\tremaining: 20s\n",
            "63:\tlearn: 0.3051892\ttotal: 5.36s\tremaining: 19.8s\n",
            "64:\tlearn: 0.3050590\ttotal: 5.43s\tremaining: 19.6s\n",
            "65:\tlearn: 0.3049270\ttotal: 5.49s\tremaining: 19.5s\n",
            "66:\tlearn: 0.3048410\ttotal: 5.54s\tremaining: 19.3s\n",
            "67:\tlearn: 0.3047435\ttotal: 5.6s\tremaining: 19.1s\n",
            "68:\tlearn: 0.3046375\ttotal: 5.66s\tremaining: 18.9s\n",
            "69:\tlearn: 0.3045229\ttotal: 5.72s\tremaining: 18.8s\n",
            "70:\tlearn: 0.3044199\ttotal: 5.77s\tremaining: 18.6s\n",
            "71:\tlearn: 0.3043183\ttotal: 5.83s\tremaining: 18.5s\n",
            "72:\tlearn: 0.3042009\ttotal: 5.88s\tremaining: 18.3s\n",
            "73:\tlearn: 0.3041107\ttotal: 5.94s\tremaining: 18.1s\n",
            "74:\tlearn: 0.3040293\ttotal: 6s\tremaining: 18s\n",
            "75:\tlearn: 0.3038978\ttotal: 6.05s\tremaining: 17.8s\n",
            "76:\tlearn: 0.3037818\ttotal: 6.12s\tremaining: 17.7s\n",
            "77:\tlearn: 0.3036441\ttotal: 6.18s\tremaining: 17.6s\n",
            "78:\tlearn: 0.3035398\ttotal: 6.23s\tremaining: 17.4s\n",
            "79:\tlearn: 0.3034122\ttotal: 6.29s\tremaining: 17.3s\n",
            "80:\tlearn: 0.3033288\ttotal: 6.35s\tremaining: 17.2s\n",
            "81:\tlearn: 0.3032343\ttotal: 6.41s\tremaining: 17s\n",
            "82:\tlearn: 0.3031467\ttotal: 6.49s\tremaining: 17s\n",
            "83:\tlearn: 0.3030397\ttotal: 6.54s\tremaining: 16.8s\n",
            "84:\tlearn: 0.3029318\ttotal: 6.6s\tremaining: 16.7s\n",
            "85:\tlearn: 0.3028431\ttotal: 6.66s\tremaining: 16.6s\n",
            "86:\tlearn: 0.3027308\ttotal: 6.72s\tremaining: 16.4s\n",
            "87:\tlearn: 0.3026140\ttotal: 6.78s\tremaining: 16.3s\n",
            "88:\tlearn: 0.3024832\ttotal: 6.83s\tremaining: 16.2s\n",
            "89:\tlearn: 0.3023818\ttotal: 6.89s\tremaining: 16.1s\n",
            "90:\tlearn: 0.3022979\ttotal: 6.95s\tremaining: 16s\n",
            "91:\tlearn: 0.3022050\ttotal: 7s\tremaining: 15.8s\n",
            "92:\tlearn: 0.3021111\ttotal: 7.07s\tremaining: 15.7s\n",
            "93:\tlearn: 0.3020097\ttotal: 7.12s\tremaining: 15.6s\n",
            "94:\tlearn: 0.3019232\ttotal: 7.18s\tremaining: 15.5s\n",
            "95:\tlearn: 0.3018065\ttotal: 7.24s\tremaining: 15.4s\n",
            "96:\tlearn: 0.3017203\ttotal: 7.3s\tremaining: 15.3s\n",
            "97:\tlearn: 0.3016595\ttotal: 7.35s\tremaining: 15.2s\n",
            "98:\tlearn: 0.3015750\ttotal: 7.41s\tremaining: 15s\n",
            "99:\tlearn: 0.3014776\ttotal: 7.47s\tremaining: 15s\n",
            "100:\tlearn: 0.3013874\ttotal: 7.54s\tremaining: 14.9s\n",
            "101:\tlearn: 0.3012903\ttotal: 7.59s\tremaining: 14.7s\n",
            "102:\tlearn: 0.3011869\ttotal: 7.65s\tremaining: 14.6s\n",
            "103:\tlearn: 0.3011018\ttotal: 7.71s\tremaining: 14.5s\n",
            "104:\tlearn: 0.3010207\ttotal: 7.77s\tremaining: 14.4s\n",
            "105:\tlearn: 0.3009386\ttotal: 7.82s\tremaining: 14.3s\n",
            "106:\tlearn: 0.3008319\ttotal: 7.87s\tremaining: 14.2s\n",
            "107:\tlearn: 0.3007684\ttotal: 7.93s\tremaining: 14.1s\n",
            "108:\tlearn: 0.3007086\ttotal: 7.99s\tremaining: 14s\n",
            "109:\tlearn: 0.3006124\ttotal: 8.04s\tremaining: 13.9s\n",
            "110:\tlearn: 0.3005378\ttotal: 8.1s\tremaining: 13.8s\n",
            "111:\tlearn: 0.3004738\ttotal: 8.15s\tremaining: 13.7s\n",
            "112:\tlearn: 0.3004284\ttotal: 8.2s\tremaining: 13.6s\n",
            "113:\tlearn: 0.3003709\ttotal: 8.26s\tremaining: 13.5s\n",
            "114:\tlearn: 0.3002631\ttotal: 8.32s\tremaining: 13.4s\n",
            "115:\tlearn: 0.3001770\ttotal: 8.37s\tremaining: 13.3s\n",
            "116:\tlearn: 0.3001046\ttotal: 8.43s\tremaining: 13.2s\n",
            "117:\tlearn: 0.3000381\ttotal: 8.5s\tremaining: 13.1s\n",
            "118:\tlearn: 0.2999634\ttotal: 8.56s\tremaining: 13s\n",
            "119:\tlearn: 0.2998250\ttotal: 8.61s\tremaining: 12.9s\n",
            "120:\tlearn: 0.2997369\ttotal: 8.68s\tremaining: 12.8s\n",
            "121:\tlearn: 0.2996877\ttotal: 8.73s\tremaining: 12.7s\n",
            "122:\tlearn: 0.2996156\ttotal: 8.78s\tremaining: 12.6s\n",
            "123:\tlearn: 0.2995249\ttotal: 8.83s\tremaining: 12.5s\n",
            "124:\tlearn: 0.2994538\ttotal: 8.89s\tremaining: 12.4s\n",
            "125:\tlearn: 0.2993661\ttotal: 8.95s\tremaining: 12.4s\n",
            "126:\tlearn: 0.2992691\ttotal: 9s\tremaining: 12.3s\n",
            "127:\tlearn: 0.2991735\ttotal: 9.06s\tremaining: 12.2s\n",
            "128:\tlearn: 0.2990943\ttotal: 9.12s\tremaining: 12.1s\n",
            "129:\tlearn: 0.2989814\ttotal: 9.18s\tremaining: 12s\n",
            "130:\tlearn: 0.2989226\ttotal: 9.23s\tremaining: 11.9s\n",
            "131:\tlearn: 0.2988913\ttotal: 9.28s\tremaining: 11.8s\n",
            "132:\tlearn: 0.2988046\ttotal: 9.34s\tremaining: 11.7s\n",
            "133:\tlearn: 0.2987321\ttotal: 9.39s\tremaining: 11.6s\n",
            "134:\tlearn: 0.2986575\ttotal: 9.45s\tremaining: 11.5s\n",
            "135:\tlearn: 0.2985567\ttotal: 9.52s\tremaining: 11.5s\n",
            "136:\tlearn: 0.2984660\ttotal: 9.58s\tremaining: 11.4s\n",
            "137:\tlearn: 0.2983750\ttotal: 9.63s\tremaining: 11.3s\n",
            "138:\tlearn: 0.2982788\ttotal: 9.69s\tremaining: 11.2s\n",
            "139:\tlearn: 0.2981852\ttotal: 9.74s\tremaining: 11.1s\n",
            "140:\tlearn: 0.2981234\ttotal: 9.8s\tremaining: 11.1s\n",
            "141:\tlearn: 0.2980476\ttotal: 9.85s\tremaining: 11s\n",
            "142:\tlearn: 0.2979381\ttotal: 9.91s\tremaining: 10.9s\n",
            "143:\tlearn: 0.2978563\ttotal: 9.96s\tremaining: 10.8s\n",
            "144:\tlearn: 0.2977856\ttotal: 10s\tremaining: 10.7s\n",
            "145:\tlearn: 0.2977246\ttotal: 10.1s\tremaining: 10.6s\n",
            "146:\tlearn: 0.2976220\ttotal: 10.1s\tremaining: 10.6s\n",
            "147:\tlearn: 0.2975369\ttotal: 10.2s\tremaining: 10.5s\n",
            "148:\tlearn: 0.2974789\ttotal: 10.2s\tremaining: 10.4s\n",
            "149:\tlearn: 0.2973882\ttotal: 10.3s\tremaining: 10.3s\n",
            "150:\tlearn: 0.2973001\ttotal: 10.4s\tremaining: 10.2s\n",
            "151:\tlearn: 0.2972090\ttotal: 10.4s\tremaining: 10.1s\n",
            "152:\tlearn: 0.2971219\ttotal: 10.5s\tremaining: 10.1s\n",
            "153:\tlearn: 0.2970222\ttotal: 10.5s\tremaining: 10s\n",
            "154:\tlearn: 0.2969093\ttotal: 10.6s\tremaining: 9.92s\n",
            "155:\tlearn: 0.2968281\ttotal: 10.7s\tremaining: 9.84s\n",
            "156:\tlearn: 0.2967263\ttotal: 10.7s\tremaining: 9.76s\n",
            "157:\tlearn: 0.2966210\ttotal: 10.8s\tremaining: 9.68s\n",
            "158:\tlearn: 0.2965504\ttotal: 10.8s\tremaining: 9.6s\n",
            "159:\tlearn: 0.2964783\ttotal: 10.9s\tremaining: 9.51s\n",
            "160:\tlearn: 0.2964046\ttotal: 10.9s\tremaining: 9.44s\n",
            "161:\tlearn: 0.2963427\ttotal: 11s\tremaining: 9.36s\n",
            "162:\tlearn: 0.2962575\ttotal: 11s\tremaining: 9.28s\n",
            "163:\tlearn: 0.2961788\ttotal: 11.1s\tremaining: 9.2s\n",
            "164:\tlearn: 0.2960948\ttotal: 11.2s\tremaining: 9.13s\n",
            "165:\tlearn: 0.2960149\ttotal: 11.2s\tremaining: 9.05s\n",
            "166:\tlearn: 0.2959279\ttotal: 11.3s\tremaining: 8.98s\n",
            "167:\tlearn: 0.2958497\ttotal: 11.3s\tremaining: 8.9s\n",
            "168:\tlearn: 0.2957886\ttotal: 11.4s\tremaining: 8.82s\n",
            "169:\tlearn: 0.2956939\ttotal: 11.4s\tremaining: 8.75s\n",
            "170:\tlearn: 0.2956129\ttotal: 11.5s\tremaining: 8.67s\n",
            "171:\tlearn: 0.2955079\ttotal: 11.6s\tremaining: 8.61s\n",
            "172:\tlearn: 0.2954052\ttotal: 11.6s\tremaining: 8.54s\n",
            "173:\tlearn: 0.2953176\ttotal: 11.7s\tremaining: 8.46s\n",
            "174:\tlearn: 0.2952305\ttotal: 11.7s\tremaining: 8.38s\n",
            "175:\tlearn: 0.2951573\ttotal: 11.8s\tremaining: 8.31s\n",
            "176:\tlearn: 0.2950935\ttotal: 11.8s\tremaining: 8.23s\n",
            "177:\tlearn: 0.2950235\ttotal: 11.9s\tremaining: 8.15s\n",
            "178:\tlearn: 0.2949640\ttotal: 12s\tremaining: 8.08s\n",
            "179:\tlearn: 0.2948692\ttotal: 12s\tremaining: 8.01s\n",
            "180:\tlearn: 0.2947949\ttotal: 12.1s\tremaining: 7.94s\n",
            "181:\tlearn: 0.2947128\ttotal: 12.1s\tremaining: 7.86s\n",
            "182:\tlearn: 0.2946368\ttotal: 12.2s\tremaining: 7.79s\n",
            "183:\tlearn: 0.2945420\ttotal: 12.2s\tremaining: 7.72s\n",
            "184:\tlearn: 0.2944359\ttotal: 12.3s\tremaining: 7.65s\n",
            "185:\tlearn: 0.2943320\ttotal: 12.4s\tremaining: 7.58s\n",
            "186:\tlearn: 0.2942238\ttotal: 12.4s\tremaining: 7.51s\n",
            "187:\tlearn: 0.2941665\ttotal: 12.5s\tremaining: 7.44s\n",
            "188:\tlearn: 0.2940753\ttotal: 12.5s\tremaining: 7.37s\n",
            "189:\tlearn: 0.2940211\ttotal: 12.6s\tremaining: 7.3s\n",
            "190:\tlearn: 0.2939299\ttotal: 12.7s\tremaining: 7.23s\n",
            "191:\tlearn: 0.2938490\ttotal: 12.7s\tremaining: 7.16s\n",
            "192:\tlearn: 0.2937732\ttotal: 12.8s\tremaining: 7.09s\n",
            "193:\tlearn: 0.2936944\ttotal: 12.8s\tremaining: 7.01s\n",
            "194:\tlearn: 0.2935956\ttotal: 12.9s\tremaining: 6.94s\n",
            "195:\tlearn: 0.2934768\ttotal: 13s\tremaining: 6.87s\n",
            "196:\tlearn: 0.2933978\ttotal: 13s\tremaining: 6.81s\n",
            "197:\tlearn: 0.2933378\ttotal: 13.1s\tremaining: 6.74s\n",
            "198:\tlearn: 0.2932455\ttotal: 13.1s\tremaining: 6.67s\n",
            "199:\tlearn: 0.2931506\ttotal: 13.2s\tremaining: 6.59s\n",
            "200:\tlearn: 0.2930617\ttotal: 13.2s\tremaining: 6.53s\n",
            "201:\tlearn: 0.2929998\ttotal: 13.3s\tremaining: 6.45s\n",
            "202:\tlearn: 0.2929071\ttotal: 13.4s\tremaining: 6.38s\n",
            "203:\tlearn: 0.2928265\ttotal: 13.4s\tremaining: 6.31s\n",
            "204:\tlearn: 0.2927515\ttotal: 13.5s\tremaining: 6.24s\n",
            "205:\tlearn: 0.2927030\ttotal: 13.5s\tremaining: 6.17s\n",
            "206:\tlearn: 0.2926201\ttotal: 13.6s\tremaining: 6.11s\n",
            "207:\tlearn: 0.2925650\ttotal: 13.6s\tremaining: 6.04s\n",
            "208:\tlearn: 0.2924710\ttotal: 13.7s\tremaining: 5.97s\n",
            "209:\tlearn: 0.2923958\ttotal: 13.8s\tremaining: 5.9s\n",
            "210:\tlearn: 0.2923291\ttotal: 13.8s\tremaining: 5.83s\n",
            "211:\tlearn: 0.2922547\ttotal: 13.9s\tremaining: 5.78s\n",
            "212:\tlearn: 0.2921392\ttotal: 14s\tremaining: 5.74s\n",
            "213:\tlearn: 0.2920718\ttotal: 14.2s\tremaining: 5.69s\n",
            "214:\tlearn: 0.2919846\ttotal: 14.3s\tremaining: 5.65s\n",
            "215:\tlearn: 0.2918872\ttotal: 14.4s\tremaining: 5.61s\n",
            "216:\tlearn: 0.2918332\ttotal: 14.5s\tremaining: 5.55s\n",
            "217:\tlearn: 0.2917351\ttotal: 14.7s\tremaining: 5.52s\n",
            "218:\tlearn: 0.2916677\ttotal: 14.8s\tremaining: 5.47s\n",
            "219:\tlearn: 0.2916046\ttotal: 14.9s\tremaining: 5.42s\n",
            "220:\tlearn: 0.2915197\ttotal: 15s\tremaining: 5.37s\n",
            "221:\tlearn: 0.2914329\ttotal: 15.2s\tremaining: 5.33s\n",
            "222:\tlearn: 0.2913483\ttotal: 15.3s\tremaining: 5.28s\n",
            "223:\tlearn: 0.2912701\ttotal: 15.4s\tremaining: 5.24s\n",
            "224:\tlearn: 0.2912143\ttotal: 15.5s\tremaining: 5.18s\n",
            "225:\tlearn: 0.2911461\ttotal: 15.7s\tremaining: 5.13s\n",
            "226:\tlearn: 0.2910565\ttotal: 15.8s\tremaining: 5.07s\n",
            "227:\tlearn: 0.2909870\ttotal: 15.9s\tremaining: 5.01s\n",
            "228:\tlearn: 0.2909093\ttotal: 16s\tremaining: 4.95s\n",
            "229:\tlearn: 0.2908460\ttotal: 16.1s\tremaining: 4.89s\n",
            "230:\tlearn: 0.2907771\ttotal: 16.2s\tremaining: 4.84s\n",
            "231:\tlearn: 0.2906948\ttotal: 16.3s\tremaining: 4.78s\n",
            "232:\tlearn: 0.2906360\ttotal: 16.5s\tremaining: 4.73s\n",
            "233:\tlearn: 0.2905843\ttotal: 16.6s\tremaining: 4.68s\n",
            "234:\tlearn: 0.2905338\ttotal: 16.7s\tremaining: 4.63s\n",
            "235:\tlearn: 0.2904521\ttotal: 16.9s\tremaining: 4.58s\n",
            "236:\tlearn: 0.2903636\ttotal: 16.9s\tremaining: 4.5s\n",
            "237:\tlearn: 0.2902463\ttotal: 17s\tremaining: 4.43s\n",
            "238:\tlearn: 0.2901730\ttotal: 17s\tremaining: 4.35s\n",
            "239:\tlearn: 0.2900831\ttotal: 17.1s\tremaining: 4.28s\n",
            "240:\tlearn: 0.2900135\ttotal: 17.2s\tremaining: 4.2s\n",
            "241:\tlearn: 0.2899423\ttotal: 17.2s\tremaining: 4.13s\n",
            "242:\tlearn: 0.2898844\ttotal: 17.3s\tremaining: 4.05s\n",
            "243:\tlearn: 0.2897995\ttotal: 17.3s\tremaining: 3.98s\n",
            "244:\tlearn: 0.2897045\ttotal: 17.4s\tremaining: 3.9s\n",
            "245:\tlearn: 0.2896252\ttotal: 17.4s\tremaining: 3.83s\n",
            "246:\tlearn: 0.2895505\ttotal: 17.5s\tremaining: 3.75s\n",
            "247:\tlearn: 0.2894827\ttotal: 17.6s\tremaining: 3.68s\n",
            "248:\tlearn: 0.2893993\ttotal: 17.6s\tremaining: 3.61s\n",
            "249:\tlearn: 0.2893222\ttotal: 17.7s\tremaining: 3.53s\n",
            "250:\tlearn: 0.2892617\ttotal: 17.7s\tremaining: 3.46s\n",
            "251:\tlearn: 0.2892078\ttotal: 17.8s\tremaining: 3.39s\n",
            "252:\tlearn: 0.2891447\ttotal: 17.9s\tremaining: 3.32s\n",
            "253:\tlearn: 0.2890802\ttotal: 17.9s\tremaining: 3.24s\n",
            "254:\tlearn: 0.2890269\ttotal: 18s\tremaining: 3.17s\n",
            "255:\tlearn: 0.2889658\ttotal: 18s\tremaining: 3.1s\n",
            "256:\tlearn: 0.2889065\ttotal: 18.1s\tremaining: 3.02s\n",
            "257:\tlearn: 0.2888290\ttotal: 18.1s\tremaining: 2.95s\n",
            "258:\tlearn: 0.2887224\ttotal: 18.2s\tremaining: 2.88s\n",
            "259:\tlearn: 0.2886735\ttotal: 18.2s\tremaining: 2.81s\n",
            "260:\tlearn: 0.2886109\ttotal: 18.3s\tremaining: 2.73s\n",
            "261:\tlearn: 0.2885108\ttotal: 18.3s\tremaining: 2.66s\n",
            "262:\tlearn: 0.2884181\ttotal: 18.4s\tremaining: 2.59s\n",
            "263:\tlearn: 0.2883310\ttotal: 18.5s\tremaining: 2.52s\n",
            "264:\tlearn: 0.2882788\ttotal: 18.5s\tremaining: 2.45s\n",
            "265:\tlearn: 0.2882037\ttotal: 18.6s\tremaining: 2.37s\n",
            "266:\tlearn: 0.2881326\ttotal: 18.6s\tremaining: 2.3s\n",
            "267:\tlearn: 0.2880622\ttotal: 18.7s\tremaining: 2.23s\n",
            "268:\tlearn: 0.2879862\ttotal: 18.7s\tremaining: 2.16s\n",
            "269:\tlearn: 0.2879057\ttotal: 18.8s\tremaining: 2.09s\n",
            "270:\tlearn: 0.2877851\ttotal: 18.9s\tremaining: 2.02s\n",
            "271:\tlearn: 0.2877041\ttotal: 18.9s\tremaining: 1.95s\n",
            "272:\tlearn: 0.2876397\ttotal: 19s\tremaining: 1.88s\n",
            "273:\tlearn: 0.2875926\ttotal: 19s\tremaining: 1.81s\n",
            "274:\tlearn: 0.2875133\ttotal: 19.1s\tremaining: 1.74s\n",
            "275:\tlearn: 0.2874344\ttotal: 19.2s\tremaining: 1.67s\n",
            "276:\tlearn: 0.2873553\ttotal: 19.2s\tremaining: 1.59s\n",
            "277:\tlearn: 0.2872791\ttotal: 19.3s\tremaining: 1.52s\n",
            "278:\tlearn: 0.2871992\ttotal: 19.3s\tremaining: 1.45s\n",
            "279:\tlearn: 0.2871131\ttotal: 19.4s\tremaining: 1.38s\n",
            "280:\tlearn: 0.2870273\ttotal: 19.4s\tremaining: 1.31s\n",
            "281:\tlearn: 0.2869316\ttotal: 19.5s\tremaining: 1.24s\n",
            "282:\tlearn: 0.2868670\ttotal: 19.5s\tremaining: 1.17s\n",
            "283:\tlearn: 0.2867918\ttotal: 19.6s\tremaining: 1.1s\n",
            "284:\tlearn: 0.2866705\ttotal: 19.7s\tremaining: 1.03s\n",
            "285:\tlearn: 0.2866075\ttotal: 19.7s\tremaining: 965ms\n",
            "286:\tlearn: 0.2865436\ttotal: 19.8s\tremaining: 896ms\n",
            "287:\tlearn: 0.2864716\ttotal: 19.8s\tremaining: 827ms\n",
            "288:\tlearn: 0.2864014\ttotal: 19.9s\tremaining: 758ms\n",
            "289:\tlearn: 0.2863270\ttotal: 20s\tremaining: 688ms\n",
            "290:\tlearn: 0.2862515\ttotal: 20s\tremaining: 619ms\n",
            "291:\tlearn: 0.2861760\ttotal: 20.1s\tremaining: 550ms\n",
            "292:\tlearn: 0.2860847\ttotal: 20.1s\tremaining: 481ms\n",
            "293:\tlearn: 0.2860244\ttotal: 20.2s\tremaining: 412ms\n",
            "294:\tlearn: 0.2859214\ttotal: 20.2s\tremaining: 343ms\n",
            "295:\tlearn: 0.2858388\ttotal: 20.3s\tremaining: 274ms\n",
            "296:\tlearn: 0.2857540\ttotal: 20.4s\tremaining: 206ms\n",
            "297:\tlearn: 0.2856857\ttotal: 20.4s\tremaining: 137ms\n",
            "298:\tlearn: 0.2855941\ttotal: 20.5s\tremaining: 68.5ms\n",
            "299:\tlearn: 0.2855162\ttotal: 20.5s\tremaining: 0us\n",
            "Best Parameters: {'learning_rate': 0.1, 'l2_leaf_reg': 9, 'iterations': 300, 'depth': 8, 'border_count': 128}\n",
            "Validation Set Performance with Best Parameters:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94     45050\n",
            "           1       0.60      0.08      0.14      6016\n",
            "\n",
            "    accuracy                           0.89     51066\n",
            "   macro avg       0.74      0.54      0.54     51066\n",
            "weighted avg       0.86      0.89      0.84     51066\n",
            "\n",
            "Confusion Matrix:\n",
            "[[32261 12789]\n",
            " [ 2502  3514]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = best_catboost.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "id": "ZnhA7G-c8VRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5959ac0e-c770-471b-f18d-dfe3a3941b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DT\n"
      ],
      "metadata": {
        "id": "ZYyOyzKnLhNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import multiprocessing\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load data\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=[\"Default\"])  # Features\n",
        "y = normalized_df[\"Default\"]  # Target variable\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Apply SMOTE to the training data only\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV with parallel processing\n",
        "n_cores = multiprocessing.cpu_count()\n",
        "random_search = RandomizedSearchCV(estimator=dt, param_distributions=param_dist, n_iter=5, cv=3, scoring='f1', random_state=42, n_jobs=n_cores)\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Evaluate model on validation set using best parameters\n",
        "best_dt = random_search.best_estimator_\n",
        "y_pred_val = best_dt.predict(X_val)\n",
        "print(\"Validation Set Performance with Best Parameters:\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_val)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmVGxfxfLja6",
        "outputId": "2a4f5fe9-9386-434e-e051-c0f825017142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': None, 'criterion': 'entropy'}\n",
            "Validation Set Performance with Best Parameters:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86     45188\n",
            "           1       0.87      0.85      0.86     45084\n",
            "\n",
            "    accuracy                           0.86     90272\n",
            "   macro avg       0.86      0.86      0.86     90272\n",
            "weighted avg       0.86      0.86      0.86     90272\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[39193  5995]\n",
            " [ 6617 38467]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = best_dt.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFGElvy2L2PV",
        "outputId": "e939661f-1931-44da-ff31-b8eb8ca79d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DT + AdaBoost\n"
      ],
      "metadata": {
        "id": "RjcZUwK83b8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The AdaBoost Classifier is another popular ensemble learning method that builds a strong classifier by combining multiple weak classifiers. It works by sequentially adding weak learners to the ensemble, with each one correcting the errors made by its predecessors. AdaBoost is particularly effective for binary classification tasks and is capable of capturing complex decision boundaries."
      ],
      "metadata": {
        "id": "QHy4cRV838rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import multiprocessing\n",
        "\n",
        "# Load data\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=[\"Default\"])  # Features\n",
        "y = normalized_df[\"Default\"]  # Target variable\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize base classifier (decision tree)\n",
        "base_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize AdaBoost Classifier with the base classifier\n",
        "adaboost = AdaBoostClassifier(base_estimator=base_classifier)\n",
        "\n",
        "# Define parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV with parallel processing\n",
        "n_cores = multiprocessing.cpu_count()\n",
        "random_search = RandomizedSearchCV(estimator=adaboost, param_distributions=param_dist, n_iter=20, cv=3, scoring='f1', random_state=42, n_jobs=n_cores)\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_adaboost = random_search.best_estimator_\n",
        "\n",
        "# Evaluate model on validation set using best parameters\n",
        "y_pred_val = best_adaboost.predict(X_val)\n",
        "print(\"Validation Set Performance with Best Parameters:\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_val)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTVGeO-o3jO-",
        "outputId": "4be55708-031f-40f2-999d-b3ffe6b28c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'n_estimators': 100, 'learning_rate': 1.0}\n",
            "Validation Set Performance with Best Parameters:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89     45050\n",
            "           1       0.20      0.23      0.21      6016\n",
            "\n",
            "    accuracy                           0.80     51066\n",
            "   macro avg       0.55      0.55      0.55     51066\n",
            "weighted avg       0.81      0.80      0.81     51066\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[39489  5561]\n",
            " [ 4636  1380]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = best_adaboost.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J0_U-K93l5Y",
        "outputId": "44b0e39d-68ce-40ef-8482-9bb8a6155101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NB random\n"
      ],
      "metadata": {
        "id": "FUoogktGLCg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import randint\n",
        "import multiprocessing\n",
        "\n",
        "# Load data\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=[\"Default\"])  # Features\n",
        "y = normalized_df[\"Default\"]  # Target variable\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Naive Bayes classifier (MultinomialNB)\n",
        "nb = MultinomialNB()\n",
        "\n",
        "# Initialize RandomizedSearchCV with parallel processing\n",
        "n_cores = multiprocessing.cpu_count()\n",
        "random_search = RandomizedSearchCV(estimator=nb, param_distributions=param_dist, n_iter=5, cv=3, scoring='f1', random_state=42, n_jobs=n_cores)\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data (No need to tune hyperparameters for Naive Bayes)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found (not applicable for Naive Bayes)\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Get the best model (No hyperparameters to tune for Naive Bayes)\n",
        "best_nb = random_search.best_estimator_\n",
        "\n",
        "# Evaluate model on validation set (No hyperparameters to tune for Naive Bayes)\n",
        "y_pred_val = best_nb.predict(X_val)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_val)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHhawsYjLGQL",
        "outputId": "90470c99-9de2-4408-8a3b-c04a0f0f27d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 1 is smaller than n_iter=5. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {}\n",
            "Validation Set Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94     45050\n",
            "           1       0.00      0.00      0.00      6016\n",
            "\n",
            "    accuracy                           0.88     51066\n",
            "   macro avg       0.44      0.50      0.47     51066\n",
            "weighted avg       0.78      0.88      0.83     51066\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[45050     0]\n",
            " [ 6016     0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = best_nb.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "id": "7Tvbcn5oLJfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes\n"
      ],
      "metadata": {
        "id": "6DvHpHPubJBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import multiprocessing\n",
        "import pandas as pd\n",
        "\n",
        "# Load the modified DataFrame\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=['Default'])  # Features\n",
        "y = normalized_df['Default']  # Target variable\n",
        "\n",
        "# Apply SMOTE to the training data only\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Gaussian Naive Bayes classifier\n",
        "classifier = GaussianNB()\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation data\n",
        "y_pred = classifier.predict(X_val)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_val, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNzD9Qs1bNkk",
        "outputId": "6de1ea0f-c2d6-4330-c60d-6cdefb06070a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.71      0.72     45188\n",
            "           1       0.72      0.75      0.73     45084\n",
            "\n",
            "    accuracy                           0.73     90272\n",
            "   macro avg       0.73      0.73      0.73     90272\n",
            "weighted avg       0.73      0.73      0.73     90272\n",
            "\n",
            "Confusion Matrix:\n",
            "[[32151 13037]\n",
            " [11356 33728]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = best_adaboost.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cOsgrbyCMEn",
        "outputId": "d5272b23-0733-418e-890b-5e7be4de52fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR edited\n"
      ],
      "metadata": {
        "id": "lYVmTHRwEr5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Load data\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=[\"Default\"])  # Features\n",
        "y = normalized_df[\"Default\"]  # Target variable\n",
        "\n",
        "# Apply standardization to the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression classifier\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Define parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'C': uniform(loc=0.01, scale= 10)\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=logreg, param_distributions=param_dist, n_iter=20, cv=5, scoring='f1', random_state=42)\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_logreg = random_search.best_estimator_\n",
        "\n",
        "# Evaluate model on validation set using best parameters\n",
        "y_pred_val = best_logreg.predict(X_val)\n",
        "print(\"Validation Set Performance with Best Parameters:\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_val)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO39TxUaEvK9",
        "outputId": "28435c27-2dcd-4d40-f1de-ca6cc485e79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 1.49816047538945}\n",
            "Validation Set Performance with Best Parameters:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94     45050\n",
            "           1       0.62      0.04      0.07      6016\n",
            "\n",
            "    accuracy                           0.88     51066\n",
            "   macro avg       0.75      0.52      0.50     51066\n",
            "weighted avg       0.85      0.88      0.84     51066\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[44914   136]\n",
            " [ 5796   220]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Apply standardization to the new applicants data\n",
        "new_applicants_scaled = scaler.transform(new_applicants)\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = logreg.predict(new_applicants_scaled)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)\n"
      ],
      "metadata": {
        "id": "qYCZxxj5ExVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n"
      ],
      "metadata": {
        "id": "cUR7ag_sCV9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the modified DataFrame\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=['Default'])  # Features\n",
        "y = normalized_df['Default']  # Target variable\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize logistic regression classifier\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data probabilities\n",
        "y_prob = classifier.predict_proba(X_test)\n",
        "\n",
        "# Manually adjust the threshold (for example, to 0.3)\n",
        "threshold = 0.08\n",
        "\n",
        "y_pred_adjusted = (y_prob[:, 1] >= threshold).astype(int)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred_adjusted)\n",
        "print(\"Classification Report with Threshold Adjustment:\")\n",
        "print(report)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_adjusted)\n",
        "print(\"\\nConfusion Matrix with Threshold Adjustment:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TawlR7txCbFG",
        "outputId": "75cce69d-c4f3-4787-ee78-1dc8afba36fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report with Threshold Adjustment:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.51      0.67     45050\n",
            "           1       0.18      0.81      0.30      6016\n",
            "\n",
            "    accuracy                           0.55     51066\n",
            "   macro avg       0.57      0.66      0.48     51066\n",
            "weighted avg       0.86      0.55      0.62     51066\n",
            "\n",
            "\n",
            "Confusion Matrix with Threshold Adjustment:\n",
            "[[23118 21932]\n",
            " [ 1136  4880]]\n",
            "[[23118 21932]\n",
            " [ 1136  4880]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess new loan applications\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "new_predictions = classifier.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "id": "jWRmlraVClqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LR edited++"
      ],
      "metadata": {
        "id": "grhxtg01GcOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from scipy.stats import uniform\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load data\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=[\"Default\"])  # Features\n",
        "y = normalized_df[\"Default\"]  # Target variable\n",
        "\n",
        "# Apply standardization to the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Handling Class Imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Split the resampled data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression classifier\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Define parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'C': uniform(loc=0.01, scale=10)\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=logreg, param_distributions=param_dist, n_iter=20, cv=5, scoring='f1', random_state=42)\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_logreg = random_search.best_estimator_\n",
        "\n",
        "# Evaluate model on validation set using best parameters\n",
        "y_pred_val = best_logreg.predict(X_val)\n",
        "print(\"Validation Set Performance with Best Parameters:\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_val)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASaD8iCGGg3H",
        "outputId": "2b301b6b-c3f8-4724-b1a4-5e5fdf9c9a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 3.7554011884736247}\n",
            "Validation Set Performance with Best Parameters:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70     45188\n",
            "           1       0.69      0.72      0.71     45084\n",
            "\n",
            "    accuracy                           0.70     90272\n",
            "   macro avg       0.70      0.70      0.70     90272\n",
            "weighted avg       0.70      0.70      0.70     90272\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[30997 14191]\n",
            " [12771 32313]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = classifier.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZddAm3kGjor",
        "outputId": "3e59d786-d772-4011-ea34-d4a90969ae19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RF edited\n"
      ],
      "metadata": {
        "id": "LvGBRUZWFdyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import randint\n",
        "import multiprocessing\n",
        "\n",
        "# Load data\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=[\"Default\"])  # Features\n",
        "y = normalized_df[\"Default\"]  # Target variable\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Define parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [int(x) for x in range(100, 1000, 100)],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV with parallel processing\n",
        "n_cores = multiprocessing.cpu_count()\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=5, cv=3, scoring='f1', random_state=42, n_jobs=n_cores)\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_rf = random_search.best_estimator_\n",
        "\n",
        "# Evaluate model on validation set using best parameters\n",
        "y_pred_val = best_rf.predict(X_val)\n",
        "print(\"Validation Set Performance with Best Parameters:\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_val)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uksdNO5FgM0",
        "outputId": "e12f0312-2585-462b-ddb6-fa5001c9e1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'entropy', 'bootstrap': False}\n",
            "Validation Set Performance with Best Parameters:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94     45050\n",
            "           1       0.64      0.05      0.09      6016\n",
            "\n",
            "    accuracy                           0.88     51066\n",
            "   macro avg       0.76      0.52      0.51     51066\n",
            "weighted avg       0.86      0.88      0.84     51066\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[44885   165]\n",
            " [ 5726   290]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = best_rf.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTAlEugRFkE0",
        "outputId": "4f6e6d8c-1572-4371-dc0d-322e21d249a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "qXY4AjRbBLhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the modified DataFrame\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=['Default'])  # Features\n",
        "y = normalized_df['Default']  # Target variable\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize SMOTE for over-sampling only the minority class (positive class)\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "\n",
        "# Apply SMOTE to the training data only\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the classifier on the resampled training data\n",
        "classifier.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KItIv74xBPAG",
        "outputId": "e527d5ff-8d36-4552-8933-c7376fce398b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.85      0.88     45050\n",
            "           1       0.25      0.37      0.30      6016\n",
            "\n",
            "    accuracy                           0.79     51066\n",
            "   macro avg       0.58      0.61      0.59     51066\n",
            "weighted avg       0.83      0.79      0.81     51066\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[38226  6824]\n",
            " [ 3774  2242]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = classifier.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-BGmPxrCuIc",
        "outputId": "2b79e144-1316-4e13-df47-d11839f16ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RF GridSearch\n"
      ],
      "metadata": {
        "id": "gkfTkkmbEt6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "latest runtime: 4hrs"
      ],
      "metadata": {
        "id": "7nrsPx8IwnCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the modified DataFrame\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=['Default'])  # Features\n",
        "y = normalized_df['Default']  # Target variable\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize SMOTE for over-sampling only the minority class (positive class)\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "\n",
        "# Apply SMOTE to the training data only\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],  # Reduced number of estimators\n",
        "    'max_depth': [5, 10],  # Reduced depth\n",
        "    'min_samples_split': [2, 5],  # Reduced number of splits\n",
        "    'min_samples_leaf': [1]  # Kept only one value for leaf samples\n",
        "}\n",
        "\n",
        "# Perform Grid Search with cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Get the best model from Grid Search\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fv457b8EyLc",
        "outputId": "c4906010-5dd3-46d0-cc4d-a22cbe09cc07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.72      0.81     45050\n",
            "           1       0.22      0.59      0.32      6016\n",
            "\n",
            "    accuracy                           0.70     51066\n",
            "   macro avg       0.57      0.65      0.56     51066\n",
            "weighted avg       0.84      0.70      0.75     51066\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[32345 12705]\n",
            " [ 2492  3524]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = classifier.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9kzl1w5Ey-l",
        "outputId": "2790d89b-6c6a-4fce-9fb1-725b701d90f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Svm"
      ],
      "metadata": {
        "id": "DAn__4RZQ7PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the modified DataFrame\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=['Default'])  # Features\n",
        "y = normalized_df['Default']  # Target variable\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize SMOTE for over-sampling only the minority class (positive class)\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "\n",
        "# Apply SMOTE to the training data only\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize Support Vector Machine (SVM) classifier\n",
        "classifier = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "# Fit the classifier on the resampled training data\n",
        "classifier.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "YP8soMx_Q95U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c32886c-76f5-4277-f334-e16da348cd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.72      0.81     45050\n",
            "           1       0.22      0.58      0.31      6016\n",
            "\n",
            "    accuracy                           0.70     51066\n",
            "   macro avg       0.57      0.65      0.56     51066\n",
            "weighted avg       0.84      0.70      0.75     51066\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[32261 12789]\n",
            " [ 2502  3514]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = classifier.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "id": "lCR4uobRRF65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc680f1-5a99-4d11-9954-d085675e9f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SVM_edited**"
      ],
      "metadata": {
        "id": "0W5coPj_R7cU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "takes too long, record: 13 hours runtime disconnect\n",
        "\n",
        "my soul died a little running this\n"
      ],
      "metadata": {
        "id": "hyzBWcpIFGBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.stats import randint\n",
        "import multiprocessing\n",
        "\n",
        "# Load data\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=[\"Default\"])  # Features\n",
        "y = normalized_df[\"Default\"]  # Target variable\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize SVM classifier\n",
        "svm = SVC()\n",
        "\n",
        "# Define parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'degree': [2],\n",
        "    'coef0': [0.0]\n",
        "}\n",
        "param_dist_reduced = {\n",
        "    'C': [0.1, 1, 10],  # Reduced range of values for C\n",
        "    'kernel': ['linear', 'rbf'],  # Focus on simpler kernels\n",
        "    'gamma': ['scale'],  # Only one option for gamma\n",
        "    'degree': [2],  # Only one degree for polynomial kernel\n",
        "    'coef0': [0.0]  # Only one value for coef0\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV with parallel processing\n",
        "n_cores = multiprocessing.cpu_count()\n",
        "random_search = RandomizedSearchCV(estimator=svm, param_distributions=param_dist, n_iter=4, cv=3, scoring='f1', random_state=42, n_jobs=n_cores)\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_svm = random_search.best_estimator_\n",
        "\n",
        "# Evaluate model on validation set using best parameters\n",
        "y_pred_val = best_svm.predict(X_val)\n",
        "print(\"Validation Set Performance with Best Parameters:\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "Md9YUg1FRlCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = classifier.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "id": "853x-eZ3SKiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network\n"
      ],
      "metadata": {
        "id": "KNX35SQ24ok2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import multiprocessing\n",
        "\n",
        "# Load data\n",
        "normalized_df = pd.read_csv('BLA.csv')\n",
        "\n",
        "# Check for and drop rows with missing target values\n",
        "normalized_df = normalized_df.dropna(subset=['Default'])\n",
        "\n",
        "# Define the features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=[\"Default\"])  # Features\n",
        "y = normalized_df[\"Default\"]  # Target variable\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Multi-layer Perceptron (Neural Network) classifier\n",
        "mlp = MLPClassifier()\n",
        "\n",
        "# Define parameter distributions for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'hidden_layer_sizes': [(100,), (50, 50), (100, 50), (50, 25)],\n",
        "    'activation': ['logistic', 'tanh', 'relu'],\n",
        "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
        "    'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV with parallel processing\n",
        "n_cores = multiprocessing.cpu_count()\n",
        "random_search = RandomizedSearchCV(estimator=mlp, param_distributions=param_dist, n_iter=20, cv=3, scoring='f1', random_state=42, n_jobs=n_cores)\n",
        "\n",
        "# Fit RandomizedSearchCV on the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_mlp = random_search.best_estimator_\n",
        "\n",
        "# Evaluate model on validation set using best parameters\n",
        "y_pred_val = best_mlp.predict(X_val)\n",
        "print(\"Validation Set Performance with Best Parameters:\")\n",
        "print(classification_report(y_val, y_pred_val))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eOBVi7Eo4rs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3e8975-cffa-4aa2-aaab-4a566c59f6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (50, 25), 'alpha': 0.0001, 'activation': 'tanh'}\n",
            "Validation Set Performance with Best Parameters:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94     45050\n",
            "           1       0.50      0.10      0.17      6016\n",
            "\n",
            "    accuracy                           0.88     51066\n",
            "   macro avg       0.70      0.54      0.55     51066\n",
            "weighted avg       0.85      0.88      0.85     51066\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load new loan applications data\n",
        "new_applicants = pd.read_csv(\"NewApplicants.csv\")\n",
        "\n",
        "# Drop the 'Default' column if it exists in the new applicants dataset\n",
        "if 'Default' in new_applicants.columns:\n",
        "    new_applicants = new_applicants.drop(columns=['Default'])\n",
        "\n",
        "# Make predictions for new loan applications\n",
        "new_predictions = best_mlp.predict(new_applicants)\n",
        "\n",
        "# Print predictions for new loan applications\n",
        "print(\"Predictions for new loan applications:\", new_predictions)"
      ],
      "metadata": {
        "id": "o9CYgsY-5DYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9beb2157-7a49-4dfb-f0dc-322093952b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new loan applications: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xpmEdBFlBIqf"
      }
    }
  ]
}